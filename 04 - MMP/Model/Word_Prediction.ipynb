{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "import numpy as np\n",
    "import re\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 581888\n"
     ]
    }
   ],
   "source": [
    "path = '1661-0.txt'\n",
    "text = open(path, encoding='utf-8').read().lower()\n",
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "tokens = tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = 3+1\n",
    "text_sequences = []\n",
    "for i in range(train_len,len(tokens)):\n",
    "    seq = tokens[i-train_len:i]\n",
    "    text_sequences.append(seq)\n",
    "sequences = {}\n",
    "count = 1\n",
    "for i in range(len(tokens)):\n",
    "    if tokens[i] not in sequences:\n",
    "        sequences[tokens[i]] = count\n",
    "        count += 1\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text_sequences)\n",
    "sequences = tokenizer.texts_to_sequences(text_sequences) \n",
    "\n",
    "#Collecting some information   \n",
    "vocabulary_size = len(tokenizer.word_counts)+1\n",
    "\n",
    "n_sequences = np.empty([len(sequences),train_len], dtype='int32')\n",
    "for i in range(len(sequences)):\n",
    "    n_sequences[i] = sequences[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109222, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs = n_sequences[:,:-1]\n",
    "train_targets = n_sequences[:,-1]\n",
    "train_targets = to_categorical(train_targets, num_classes=vocabulary_size)\n",
    "seq_len = train_inputs.shape[1]\n",
    "train_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 3, 3)              24606     \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 3, 50)             10800     \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8202)              418302    \n",
      "=================================================================\n",
      "Total params: 476,458\n",
      "Trainable params: 476,458\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosha\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "109222/109222 [==============================] - 41s 378us/step - loss: 6.7191 - accuracy: 0.0530\n",
      "Epoch 2/500\n",
      "109222/109222 [==============================] - 38s 349us/step - loss: 6.4053 - accuracy: 0.0532\n",
      "Epoch 3/500\n",
      "109222/109222 [==============================] - 37s 338us/step - loss: 6.2394 - accuracy: 0.0535\n",
      "Epoch 4/500\n",
      "109222/109222 [==============================] - 33s 306us/step - loss: 6.0307 - accuracy: 0.0717\n",
      "Epoch 5/500\n",
      "109222/109222 [==============================] - 38s 349us/step - loss: 5.8646 - accuracy: 0.0796\n",
      "Epoch 6/500\n",
      "109222/109222 [==============================] - 37s 341us/step - loss: 5.7484 - accuracy: 0.0875\n",
      "Epoch 7/500\n",
      "109222/109222 [==============================] - 37s 338us/step - loss: 5.6511 - accuracy: 0.0929\n",
      "Epoch 8/500\n",
      "109222/109222 [==============================] - 36s 334us/step - loss: 5.5562 - accuracy: 0.1020\n",
      "Epoch 9/500\n",
      "109222/109222 [==============================] - 36s 333us/step - loss: 5.4635 - accuracy: 0.1087\n",
      "Epoch 10/500\n",
      "109222/109222 [==============================] - 36s 334us/step - loss: 5.3806 - accuracy: 0.1137s - loss: 5.3820 - accura\n",
      "Epoch 11/500\n",
      "109222/109222 [==============================] - 36s 333us/step - loss: 5.3038 - accuracy: 0.1184\n",
      "Epoch 12/500\n",
      "109222/109222 [==============================] - 37s 336us/step - loss: 5.2336 - accuracy: 0.1208\n",
      "Epoch 13/500\n",
      "109222/109222 [==============================] - 37s 341us/step - loss: 5.1632 - accuracy: 0.1239\n",
      "Epoch 14/500\n",
      "109222/109222 [==============================] - 37s 342us/step - loss: 5.0922 - accuracy: 0.1261\n",
      "Epoch 15/500\n",
      "109222/109222 [==============================] - 45s 414us/step - loss: 5.0235 - accuracy: 0.1280\n",
      "Epoch 16/500\n",
      "109222/109222 [==============================] - 36s 332us/step - loss: 4.9592 - accuracy: 0.1300\n",
      "Epoch 17/500\n",
      "109222/109222 [==============================] - 36s 333us/step - loss: 4.8993 - accuracy: 0.1318\n",
      "Epoch 18/500\n",
      "109222/109222 [==============================] - 36s 333us/step - loss: 4.8424 - accuracy: 0.1339\n",
      "Epoch 19/500\n",
      "109222/109222 [==============================] - 36s 333us/step - loss: 4.7889 - accuracy: 0.1353\n",
      "Epoch 20/500\n",
      "109222/109222 [==============================] - 36s 334us/step - loss: 4.7397 - accuracy: 0.1369\n",
      "Epoch 21/500\n",
      "109222/109222 [==============================] - 36s 331us/step - loss: 4.6921 - accuracy: 0.1385\n",
      "Epoch 22/500\n",
      "109222/109222 [==============================] - 39s 355us/step - loss: 4.6482 - accuracy: 0.1404s - loss: 4.646\n",
      "Epoch 23/500\n",
      "109222/109222 [==============================] - 43s 395us/step - loss: 4.6076 - accuracy: 0.1425\n",
      "Epoch 24/500\n",
      "109222/109222 [==============================] - 38s 350us/step - loss: 4.5695 - accuracy: 0.1437\n",
      "Epoch 25/500\n",
      "109222/109222 [==============================] - 36s 334us/step - loss: 4.5343 - accuracy: 0.1448\n",
      "Epoch 26/500\n",
      "109222/109222 [==============================] - 36s 330us/step - loss: 4.5014 - accuracy: 0.1480\n",
      "Epoch 27/500\n",
      "109222/109222 [==============================] - 36s 334us/step - loss: 4.4713 - accuracy: 0.1496\n",
      "Epoch 28/500\n",
      "109222/109222 [==============================] - 36s 334us/step - loss: 4.4423 - accuracy: 0.1515\n",
      "Epoch 29/500\n",
      "109222/109222 [==============================] - 37s 336us/step - loss: 4.4165 - accuracy: 0.1541\n",
      "Epoch 30/500\n",
      "109222/109222 [==============================] - 36s 331us/step - loss: 4.3934 - accuracy: 0.1561\n",
      "Epoch 31/500\n",
      "109222/109222 [==============================] - 38s 346us/step - loss: 4.3686 - accuracy: 0.1572\n",
      "Epoch 32/500\n",
      "109222/109222 [==============================] - 36s 333us/step - loss: 4.3475 - accuracy: 0.1601\n",
      "Epoch 33/500\n",
      "109222/109222 [==============================] - 37s 335us/step - loss: 4.3273 - accuracy: 0.1616\n",
      "Epoch 34/500\n",
      "109222/109222 [==============================] - ETA: 0s - loss: 4.3074 - accuracy: 0.1636 E - 37s 339us/step - loss: 4.3074 - accuracy: 0.1636\n",
      "Epoch 35/500\n",
      "109222/109222 [==============================] - 37s 337us/step - loss: 4.2898 - accuracy: 0.1644\n",
      "Epoch 36/500\n",
      "109222/109222 [==============================] - 37s 339us/step - loss: 4.2715 - accuracy: 0.1667\n",
      "Epoch 37/500\n",
      "109222/109222 [==============================] - 38s 351us/step - loss: 4.2554 - accuracy: 0.1669\n",
      "Epoch 38/500\n",
      "109222/109222 [==============================] - 38s 346us/step - loss: 4.2396 - accuracy: 0.1688\n",
      "Epoch 39/500\n",
      "109222/109222 [==============================] - 38s 348us/step - loss: 4.2249 - accuracy: 0.1696\n",
      "Epoch 40/500\n",
      "109222/109222 [==============================] - 37s 340us/step - loss: 4.2091 - accuracy: 0.1720\n",
      "Epoch 41/500\n",
      "109222/109222 [==============================] - 37s 339us/step - loss: 4.1966 - accuracy: 0.1733\n",
      "Epoch 42/500\n",
      "109222/109222 [==============================] - 37s 338us/step - loss: 4.1825 - accuracy: 0.1744s - loss: 4.1831 - accura\n",
      "Epoch 43/500\n",
      "109222/109222 [==============================] - 38s 349us/step - loss: 4.1697 - accuracy: 0.1759\n",
      "Epoch 44/500\n",
      "109222/109222 [==============================] - 45s 415us/step - loss: 4.1571 - accuracy: 0.1771\n",
      "Epoch 45/500\n",
      "109222/109222 [==============================] - 38s 345us/step - loss: 4.1435 - accuracy: 0.1785\n",
      "Epoch 46/500\n",
      "109222/109222 [==============================] - 38s 345us/step - loss: 4.1330 - accuracy: 0.1791s - loss: 4\n",
      "Epoch 47/500\n",
      "109222/109222 [==============================] - 45s 410us/step - loss: 4.1221 - accuracy: 0.1803s - loss: 4.1217 - accuracy: 0.\n",
      "Epoch 48/500\n",
      "109222/109222 [==============================] - 42s 383us/step - loss: 4.1117 - accuracy: 0.1820\n",
      "Epoch 49/500\n",
      "109222/109222 [==============================] - 38s 347us/step - loss: 4.1001 - accuracy: 0.1835\n",
      "Epoch 50/500\n",
      "109222/109222 [==============================] - 38s 348us/step - loss: 4.0906 - accuracy: 0.1843s - los\n",
      "Epoch 51/500\n",
      "109222/109222 [==============================] - 38s 351us/step - loss: 4.0800 - accuracy: 0.1860s - loss: 4.0793 - accuracy: 0.18\n",
      "Epoch 52/500\n",
      "109222/109222 [==============================] - 38s 352us/step - loss: 4.0692 - accuracy: 0.1854\n",
      "Epoch 53/500\n",
      "109222/109222 [==============================] - 38s 352us/step - loss: 4.0588 - accuracy: 0.1870\n",
      "Epoch 54/500\n",
      "109222/109222 [==============================] - 38s 351us/step - loss: 4.0524 - accuracy: 0.1868\n",
      "Epoch 55/500\n",
      "109222/109222 [==============================] - 39s 354us/step - loss: 4.0423 - accuracy: 0.1884\n",
      "Epoch 56/500\n",
      "109222/109222 [==============================] - 39s 354us/step - loss: 4.0332 - accuracy: 0.1904\n",
      "Epoch 57/500\n",
      "109222/109222 [==============================] - 39s 355us/step - loss: 4.0245 - accuracy: 0.1904s - loss: 4.0246 - accura\n",
      "Epoch 58/500\n",
      "109222/109222 [==============================] - 39s 359us/step - loss: 4.0163 - accuracy: 0.1919\n",
      "Epoch 59/500\n",
      "109222/109222 [==============================] - 39s 359us/step - loss: 4.0085 - accuracy: 0.1916\n",
      "Epoch 60/500\n",
      "109222/109222 [==============================] - 39s 361us/step - loss: 4.0012 - accuracy: 0.1936\n",
      "Epoch 61/500\n",
      "109222/109222 [==============================] - 40s 363us/step - loss: 3.9923 - accuracy: 0.1943\n",
      "Epoch 62/500\n",
      "109222/109222 [==============================] - 39s 360us/step - loss: 3.9855 - accuracy: 0.1944\n",
      "Epoch 63/500\n",
      "109222/109222 [==============================] - 40s 363us/step - loss: 3.9778 - accuracy: 0.1953\n",
      "Epoch 64/500\n",
      "109222/109222 [==============================] - 40s 363us/step - loss: 3.9717 - accuracy: 0.1973\n",
      "Epoch 65/500\n",
      "109222/109222 [==============================] - 40s 364us/step - loss: 3.9623 - accuracy: 0.1975s - loss: 3 - ETA\n",
      "Epoch 66/500\n",
      "109222/109222 [==============================] - 40s 366us/step - loss: 3.9551 - accuracy: 0.1981\n",
      "Epoch 67/500\n",
      "109222/109222 [==============================] - 40s 368us/step - loss: 3.9498 - accuracy: 0.2000\n",
      "Epoch 68/500\n",
      "109222/109222 [==============================] - 40s 367us/step - loss: 3.9422 - accuracy: 0.2014\n",
      "Epoch 69/500\n",
      "109222/109222 [==============================] - 43s 397us/step - loss: 3.9364 - accuracy: 0.2007\n",
      "Epoch 70/500\n",
      "109222/109222 [==============================] - 49s 448us/step - loss: 3.9295 - accuracy: 0.2020\n",
      "Epoch 71/500\n",
      "109222/109222 [==============================] - ETA: 0s - loss: 3.9230 - accuracy: 0.20 - 53s 489us/step - loss: 3.9230 - accuracy: 0.2032\n",
      "Epoch 72/500\n",
      "109222/109222 [==============================] - 42s 384us/step - loss: 3.9170 - accuracy: 0.2040\n",
      "Epoch 73/500\n",
      "109222/109222 [==============================] - 49s 450us/step - loss: 3.9119 - accuracy: 0.2044s - loss: 3.9115 - accuracy: 0.\n",
      "Epoch 74/500\n",
      "109222/109222 [==============================] - 45s 409us/step - loss: 3.9070 - accuracy: 0.2048\n",
      "Epoch 75/500\n",
      "109222/109222 [==============================] - 44s 407us/step - loss: 3.8985 - accuracy: 0.2062\n",
      "Epoch 76/500\n",
      "109222/109222 [==============================] - 41s 375us/step - loss: 3.8931 - accuracy: 0.2064\n",
      "Epoch 77/500\n",
      "109222/109222 [==============================] - 43s 392us/step - loss: 3.8868 - accuracy: 0.2066\n",
      "Epoch 78/500\n",
      "109222/109222 [==============================] - 42s 382us/step - loss: 3.8830 - accuracy: 0.2086\n",
      "Epoch 79/500\n",
      "109222/109222 [==============================] - 41s 378us/step - loss: 3.8766 - accuracy: 0.2090\n",
      "Epoch 80/500\n",
      "109222/109222 [==============================] - 43s 391us/step - loss: 3.8710 - accuracy: 0.2089\n",
      "Epoch 81/500\n",
      "109222/109222 [==============================] - 42s 385us/step - loss: 3.8653 - accuracy: 0.2090\n",
      "Epoch 82/500\n",
      "109222/109222 [==============================] - 42s 383us/step - loss: 3.8615 - accuracy: 0.2108\n",
      "Epoch 83/500\n",
      "109222/109222 [==============================] - 43s 395us/step - loss: 3.8549 - accuracy: 0.2114\n",
      "Epoch 84/500\n",
      "109222/109222 [==============================] - 42s 388us/step - loss: 3.8500 - accuracy: 0.2114\n",
      "Epoch 85/500\n",
      "109222/109222 [==============================] - 43s 397us/step - loss: 3.8459 - accuracy: 0.2130\n",
      "Epoch 86/500\n",
      "109222/109222 [==============================] - 48s 439us/step - loss: 3.8408 - accuracy: 0.2123\n",
      "Epoch 87/500\n",
      "109222/109222 [==============================] - 44s 405us/step - loss: 3.8351 - accuracy: 0.2140\n",
      "Epoch 88/500\n",
      "109222/109222 [==============================] - 42s 387us/step - loss: 3.8292 - accuracy: 0.2143\n",
      "Epoch 89/500\n",
      "109222/109222 [==============================] - 43s 393us/step - loss: 3.8265 - accuracy: 0.2149\n",
      "Epoch 90/500\n",
      "109222/109222 [==============================] - 44s 401us/step - loss: 3.8215 - accuracy: 0.2148\n",
      "Epoch 91/500\n",
      "109222/109222 [==============================] - 51s 471us/step - loss: 3.8162 - accuracy: 0.2164\n",
      "Epoch 92/500\n",
      "109222/109222 [==============================] - 43s 397us/step - loss: 3.8129 - accuracy: 0.2164\n",
      "Epoch 93/500\n",
      "109222/109222 [==============================] - 45s 408us/step - loss: 3.8087 - accuracy: 0.2168\n",
      "Epoch 94/500\n",
      "109222/109222 [==============================] - 39s 353us/step - loss: 3.8039 - accuracy: 0.2186\n",
      "Epoch 95/500\n",
      "109222/109222 [==============================] - 44s 400us/step - loss: 3.7985 - accuracy: 0.2181\n",
      "Epoch 96/500\n",
      "109222/109222 [==============================] - 44s 406us/step - loss: 3.7952 - accuracy: 0.2190\n",
      "Epoch 97/500\n",
      "109222/109222 [==============================] - 35s 324us/step - loss: 3.7898 - accuracy: 0.2192\n",
      "Epoch 98/500\n",
      "109222/109222 [==============================] - 22s 202us/step - loss: 3.7868 - accuracy: 0.2190\n",
      "Epoch 99/500\n",
      "109222/109222 [==============================] - 22s 198us/step - loss: 3.7806 - accuracy: 0.2201\n",
      "Epoch 100/500\n",
      "109222/109222 [==============================] - 21s 191us/step - loss: 3.7778 - accuracy: 0.2210\n",
      "Epoch 101/500\n",
      "109222/109222 [==============================] - 21s 191us/step - loss: 3.7739 - accuracy: 0.2213\n",
      "Epoch 102/500\n",
      "109222/109222 [==============================] - 21s 193us/step - loss: 3.7701 - accuracy: 0.2213\n",
      "Epoch 103/500\n",
      "109222/109222 [==============================] - 20s 185us/step - loss: 3.7667 - accuracy: 0.2224\n",
      "Epoch 104/500\n",
      "109222/109222 [==============================] - 19s 178us/step - loss: 3.7624 - accuracy: 0.2228\n",
      "Epoch 105/500\n",
      "109222/109222 [==============================] - 20s 182us/step - loss: 3.7581 - accuracy: 0.2235\n",
      "Epoch 106/500\n",
      "109222/109222 [==============================] - 20s 184us/step - loss: 3.7549 - accuracy: 0.2239\n",
      "Epoch 107/500\n",
      "109222/109222 [==============================] - 20s 180us/step - loss: 3.7493 - accuracy: 0.2253\n",
      "Epoch 108/500\n",
      "109222/109222 [==============================] - 20s 185us/step - loss: 3.7490 - accuracy: 0.2243\n",
      "Epoch 109/500\n",
      "109222/109222 [==============================] - 20s 184us/step - loss: 3.7428 - accuracy: 0.2255\n",
      "Epoch 110/500\n",
      "109222/109222 [==============================] - 20s 180us/step - loss: 3.7379 - accuracy: 0.2275\n",
      "Epoch 111/500\n",
      "109222/109222 [==============================] - 20s 182us/step - loss: 3.7368 - accuracy: 0.2263\n",
      "Epoch 112/500\n",
      "109222/109222 [==============================] - 20s 184us/step - loss: 3.7324 - accuracy: 0.2274\n",
      "Epoch 113/500\n",
      "109222/109222 [==============================] - 20s 180us/step - loss: 3.7280 - accuracy: 0.2273\n",
      "Epoch 114/500\n",
      "109222/109222 [==============================] - 20s 182us/step - loss: 3.7261 - accuracy: 0.2281\n",
      "Epoch 115/500\n",
      "109222/109222 [==============================] - 21s 194us/step - loss: 3.7222 - accuracy: 0.2284\n",
      "Epoch 116/500\n",
      "109222/109222 [==============================] - 20s 181us/step - loss: 3.7174 - accuracy: 0.2284\n",
      "Epoch 117/500\n",
      "109222/109222 [==============================] - 20s 182us/step - loss: 3.7135 - accuracy: 0.2300\n",
      "Epoch 118/500\n",
      "109222/109222 [==============================] - 20s 183us/step - loss: 3.7139 - accuracy: 0.2301\n",
      "Epoch 119/500\n",
      "109222/109222 [==============================] - 20s 182us/step - loss: 3.7077 - accuracy: 0.2300\n",
      "Epoch 120/500\n",
      "109222/109222 [==============================] - 20s 184us/step - loss: 3.7050 - accuracy: 0.2310\n",
      "Epoch 121/500\n",
      "109222/109222 [==============================] - 20s 187us/step - loss: 3.7011 - accuracy: 0.2311\n",
      "Epoch 122/500\n",
      "109222/109222 [==============================] - 20s 182us/step - loss: 3.6971 - accuracy: 0.2319\n",
      "Epoch 123/500\n",
      "109222/109222 [==============================] - 20s 184us/step - loss: 3.6948 - accuracy: 0.2320\n",
      "Epoch 124/500\n",
      "109222/109222 [==============================] - 20s 185us/step - loss: 3.6910 - accuracy: 0.2330\n",
      "Epoch 125/500\n",
      "109222/109222 [==============================] - 20s 187us/step - loss: 3.6891 - accuracy: 0.2339\n",
      "Epoch 126/500\n",
      "109222/109222 [==============================] - 20s 186us/step - loss: 3.6864 - accuracy: 0.2333\n",
      "Epoch 127/500\n",
      "109222/109222 [==============================] - 20s 187us/step - loss: 3.6830 - accuracy: 0.2347\n",
      "Epoch 128/500\n",
      "109222/109222 [==============================] - 20s 185us/step - loss: 3.6808 - accuracy: 0.2349\n",
      "Epoch 129/500\n",
      "109222/109222 [==============================] - 20s 183us/step - loss: 3.6781 - accuracy: 0.2346\n",
      "Epoch 130/500\n",
      "109222/109222 [==============================] - 20s 183us/step - loss: 3.6718 - accuracy: 0.2363\n",
      "Epoch 131/500\n",
      "109222/109222 [==============================] - 20s 185us/step - loss: 3.6691 - accuracy: 0.2365\n",
      "Epoch 132/500\n",
      "109222/109222 [==============================] - 20s 188us/step - loss: 3.6682 - accuracy: 0.2361\n",
      "Epoch 133/500\n",
      "109222/109222 [==============================] - 21s 192us/step - loss: 3.6646 - accuracy: 0.2364\n",
      "Epoch 134/500\n",
      "109222/109222 [==============================] - 22s 201us/step - loss: 3.6609 - accuracy: 0.2370\n",
      "Epoch 135/500\n",
      "109222/109222 [==============================] - 21s 190us/step - loss: 3.6613 - accuracy: 0.2372\n",
      "Epoch 136/500\n",
      "109222/109222 [==============================] - 20s 185us/step - loss: 3.6551 - accuracy: 0.2381\n",
      "Epoch 137/500\n",
      "109222/109222 [==============================] - 20s 186us/step - loss: 3.6544 - accuracy: 0.2384\n",
      "Epoch 138/500\n",
      "109222/109222 [==============================] - 21s 190us/step - loss: 3.6515 - accuracy: 0.2389\n",
      "Epoch 139/500\n",
      "109222/109222 [==============================] - 20s 184us/step - loss: 3.6475 - accuracy: 0.2393\n",
      "Epoch 140/500\n",
      "109222/109222 [==============================] - 20s 184us/step - loss: 3.6444 - accuracy: 0.2406\n",
      "Epoch 141/500\n",
      "109222/109222 [==============================] - 20s 187us/step - loss: 3.6408 - accuracy: 0.2406\n",
      "Epoch 142/500\n",
      "109222/109222 [==============================] - 20s 186us/step - loss: 3.6406 - accuracy: 0.2403\n",
      "Epoch 143/500\n",
      "109222/109222 [==============================] - 20s 185us/step - loss: 3.6373 - accuracy: 0.2409\n",
      "Epoch 144/500\n",
      "109222/109222 [==============================] - 21s 191us/step - loss: 3.6350 - accuracy: 0.2404\n",
      "Epoch 145/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109222/109222 [==============================] - 20s 185us/step - loss: 3.6318 - accuracy: 0.2411\n",
      "Epoch 146/500\n",
      "109222/109222 [==============================] - 20s 185us/step - loss: 3.6267 - accuracy: 0.2431\n",
      "Epoch 147/500\n",
      "109222/109222 [==============================] - 20s 187us/step - loss: 3.6268 - accuracy: 0.2428\n",
      "Epoch 148/500\n",
      "109222/109222 [==============================] - 20s 186us/step - loss: 3.6237 - accuracy: 0.2422\n",
      "Epoch 149/500\n",
      "109222/109222 [==============================] - 20s 186us/step - loss: 3.6216 - accuracy: 0.2431\n",
      "Epoch 150/500\n",
      "109222/109222 [==============================] - 21s 193us/step - loss: 3.6182 - accuracy: 0.2441\n",
      "Epoch 151/500\n",
      "109222/109222 [==============================] - 20s 186us/step - loss: 3.6152 - accuracy: 0.2435\n",
      "Epoch 152/500\n",
      "109222/109222 [==============================] - 20s 185us/step - loss: 3.6141 - accuracy: 0.2445\n",
      "Epoch 153/500\n",
      "109222/109222 [==============================] - 20s 186us/step - loss: 3.6130 - accuracy: 0.2437\n",
      "Epoch 154/500\n",
      "109222/109222 [==============================] - 20s 187us/step - loss: 3.6089 - accuracy: 0.2457\n",
      "Epoch 155/500\n",
      "109222/109222 [==============================] - 20s 187us/step - loss: 3.6074 - accuracy: 0.2450\n",
      "Epoch 156/500\n",
      "109222/109222 [==============================] - 21s 192us/step - loss: 3.6042 - accuracy: 0.2467\n",
      "Epoch 157/500\n",
      "109222/109222 [==============================] - 20s 187us/step - loss: 3.6027 - accuracy: 0.2454\n",
      "Epoch 158/500\n",
      "109222/109222 [==============================] - 21s 195us/step - loss: 3.5970 - accuracy: 0.2474\n",
      "Epoch 159/500\n",
      "109222/109222 [==============================] - 22s 200us/step - loss: 3.5972 - accuracy: 0.2466\n",
      "Epoch 160/500\n",
      "109222/109222 [==============================] - 22s 202us/step - loss: 3.5949 - accuracy: 0.2470\n",
      "Epoch 161/500\n",
      "109222/109222 [==============================] - 22s 203us/step - loss: 3.5933 - accuracy: 0.2469\n",
      "Epoch 162/500\n",
      "109222/109222 [==============================] - 22s 201us/step - loss: 3.5911 - accuracy: 0.2465\n",
      "Epoch 163/500\n",
      "109222/109222 [==============================] - 22s 201us/step - loss: 3.5864 - accuracy: 0.2480\n",
      "Epoch 164/500\n",
      "109222/109222 [==============================] - 22s 200us/step - loss: 3.5844 - accuracy: 0.2487\n",
      "Epoch 165/500\n",
      "109222/109222 [==============================] - 22s 201us/step - loss: 3.5844 - accuracy: 0.2479\n",
      "Epoch 166/500\n",
      "109222/109222 [==============================] - 22s 202us/step - loss: 3.5801 - accuracy: 0.2486\n",
      "Epoch 167/500\n",
      "109222/109222 [==============================] - 22s 205us/step - loss: 3.5779 - accuracy: 0.2509\n",
      "Epoch 168/500\n",
      "109222/109222 [==============================] - 22s 201us/step - loss: 3.5781 - accuracy: 0.2492\n",
      "Epoch 169/500\n",
      "109222/109222 [==============================] - 22s 205us/step - loss: 3.5737 - accuracy: 0.2504\n",
      "Epoch 170/500\n",
      "109222/109222 [==============================] - 23s 208us/step - loss: 3.5703 - accuracy: 0.2504\n",
      "Epoch 171/500\n",
      "109222/109222 [==============================] - 22s 203us/step - loss: 3.5699 - accuracy: 0.2510\n",
      "Epoch 172/500\n",
      "109222/109222 [==============================] - 23s 208us/step - loss: 3.5686 - accuracy: 0.2498\n",
      "Epoch 173/500\n",
      "109222/109222 [==============================] - 22s 203us/step - loss: 3.5653 - accuracy: 0.2514s - loss: 3.5642 - ac\n",
      "Epoch 174/500\n",
      "109222/109222 [==============================] - 22s 203us/step - loss: 3.5640 - accuracy: 0.2521\n",
      "Epoch 175/500\n",
      "109222/109222 [==============================] - 22s 205us/step - loss: 3.5621 - accuracy: 0.2507\n",
      "Epoch 176/500\n",
      "109222/109222 [==============================] - 22s 204us/step - loss: 3.5582 - accuracy: 0.2530\n",
      "Epoch 177/500\n",
      "109222/109222 [==============================] - 24s 218us/step - loss: 3.5569 - accuracy: 0.2515\n",
      "Epoch 178/500\n",
      "109222/109222 [==============================] - 23s 211us/step - loss: 3.5545 - accuracy: 0.2530\n",
      "Epoch 179/500\n",
      "109222/109222 [==============================] - 22s 205us/step - loss: 3.5522 - accuracy: 0.2530\n",
      "Epoch 180/500\n",
      "109222/109222 [==============================] - 22s 205us/step - loss: 3.5490 - accuracy: 0.2538\n",
      "Epoch 181/500\n",
      "109222/109222 [==============================] - 22s 204us/step - loss: 3.5476 - accuracy: 0.2535\n",
      "Epoch 182/500\n",
      "109222/109222 [==============================] - 22s 203us/step - loss: 3.5486 - accuracy: 0.2536\n",
      "Epoch 183/500\n",
      "109222/109222 [==============================] - 23s 212us/step - loss: 3.5441 - accuracy: 0.2544\n",
      "Epoch 184/500\n",
      "109222/109222 [==============================] - 22s 204us/step - loss: 3.5448 - accuracy: 0.2542\n",
      "Epoch 185/500\n",
      "109222/109222 [==============================] - 22s 204us/step - loss: 3.5407 - accuracy: 0.2552\n",
      "Epoch 186/500\n",
      "109222/109222 [==============================] - 22s 205us/step - loss: 3.5376 - accuracy: 0.2556\n",
      "Epoch 187/500\n",
      "109222/109222 [==============================] - 22s 205us/step - loss: 3.5372 - accuracy: 0.2556\n",
      "Epoch 188/500\n",
      "109222/109222 [==============================] - 23s 211us/step - loss: 3.5344 - accuracy: 0.2558s - loss: 3.5347 - accuracy: 0.25\n",
      "Epoch 189/500\n",
      "109222/109222 [==============================] - 23s 207us/step - loss: 3.5319 - accuracy: 0.2560\n",
      "Epoch 190/500\n",
      "109222/109222 [==============================] - 22s 205us/step - loss: 3.5287 - accuracy: 0.2559\n",
      "Epoch 191/500\n",
      "109222/109222 [==============================] - 23s 208us/step - loss: 3.5288 - accuracy: 0.2561\n",
      "Epoch 192/500\n",
      "109222/109222 [==============================] - 22s 206us/step - loss: 3.5271 - accuracy: 0.2569\n",
      "Epoch 193/500\n",
      "109222/109222 [==============================] - 23s 207us/step - loss: 3.5248 - accuracy: 0.2573\n",
      "Epoch 194/500\n",
      "109222/109222 [==============================] - 23s 207us/step - loss: 3.5237 - accuracy: 0.2578\n",
      "Epoch 195/500\n",
      "109222/109222 [==============================] - 22s 206us/step - loss: 3.5211 - accuracy: 0.2580\n",
      "Epoch 196/500\n",
      "109222/109222 [==============================] - 22s 206us/step - loss: 3.5191 - accuracy: 0.2578\n",
      "Epoch 197/500\n",
      "109222/109222 [==============================] - 22s 204us/step - loss: 3.5170 - accuracy: 0.2579\n",
      "Epoch 198/500\n",
      "109222/109222 [==============================] - 23s 207us/step - loss: 3.5142 - accuracy: 0.2592\n",
      "Epoch 199/500\n",
      "109222/109222 [==============================] - 24s 221us/step - loss: 3.5137 - accuracy: 0.2588\n",
      "Epoch 200/500\n",
      "109222/109222 [==============================] - 23s 206us/step - loss: 3.5127 - accuracy: 0.2590s - l\n",
      "Epoch 201/500\n",
      "109222/109222 [==============================] - 23s 206us/step - loss: 3.5076 - accuracy: 0.2605\n",
      "Epoch 202/500\n",
      "109222/109222 [==============================] - 22s 205us/step - loss: 3.5099 - accuracy: 0.2600\n",
      "Epoch 203/500\n",
      "109222/109222 [==============================] - 23s 206us/step - loss: 3.5052 - accuracy: 0.2596\n",
      "Epoch 204/500\n",
      "109222/109222 [==============================] - 23s 213us/step - loss: 3.5037 - accuracy: 0.2605\n",
      "Epoch 205/500\n",
      "109222/109222 [==============================] - 22s 205us/step - loss: 3.5021 - accuracy: 0.2602\n",
      "Epoch 206/500\n",
      "109222/109222 [==============================] - 22s 205us/step - loss: 3.5012 - accuracy: 0.2602\n",
      "Epoch 207/500\n",
      "109222/109222 [==============================] - 23s 207us/step - loss: 3.5022 - accuracy: 0.2600\n",
      "Epoch 208/500\n",
      "109222/109222 [==============================] - 22s 205us/step - loss: 3.4965 - accuracy: 0.2610\n",
      "Epoch 209/500\n",
      "109222/109222 [==============================] - 23s 210us/step - loss: 3.4926 - accuracy: 0.2623\n",
      "Epoch 210/500\n",
      "109222/109222 [==============================] - 23s 207us/step - loss: 3.4922 - accuracy: 0.2618\n",
      "Epoch 211/500\n",
      "109222/109222 [==============================] - 22s 205us/step - loss: 3.4895 - accuracy: 0.2624\n",
      "Epoch 212/500\n",
      "109222/109222 [==============================] - 22s 205us/step - loss: 3.4909 - accuracy: 0.2619\n",
      "Epoch 213/500\n",
      "109222/109222 [==============================] - 22s 205us/step - loss: 3.4895 - accuracy: 0.2628\n",
      "Epoch 214/500\n",
      "109222/109222 [==============================] - 22s 206us/step - loss: 3.4882 - accuracy: 0.2624\n",
      "Epoch 215/500\n",
      "109222/109222 [==============================] - 23s 212us/step - loss: 3.4841 - accuracy: 0.2619\n",
      "Epoch 216/500\n",
      "109222/109222 [==============================] - 22s 205us/step - loss: 3.4839 - accuracy: 0.2625\n",
      "Epoch 217/500\n",
      "109222/109222 [==============================] - 23s 210us/step - loss: 3.4788 - accuracy: 0.2632\n",
      "Epoch 218/500\n",
      "109222/109222 [==============================] - 23s 207us/step - loss: 3.4817 - accuracy: 0.2642\n",
      "Epoch 219/500\n",
      "109222/109222 [==============================] - 22s 200us/step - loss: 3.4783 - accuracy: 0.2636\n",
      "Epoch 220/500\n",
      "109222/109222 [==============================] - 22s 204us/step - loss: 3.4766 - accuracy: 0.2639\n",
      "Epoch 221/500\n",
      "109222/109222 [==============================] - 22s 201us/step - loss: 3.4732 - accuracy: 0.2634\n",
      "Epoch 222/500\n",
      "109222/109222 [==============================] - 22s 199us/step - loss: 3.4719 - accuracy: 0.2647\n",
      "Epoch 223/500\n",
      "109222/109222 [==============================] - 22s 202us/step - loss: 3.4723 - accuracy: 0.2648\n",
      "Epoch 224/500\n",
      "109222/109222 [==============================] - 23s 212us/step - loss: 3.4685 - accuracy: 0.2660\n",
      "Epoch 225/500\n",
      "109222/109222 [==============================] - 22s 203us/step - loss: 3.4666 - accuracy: 0.2656\n",
      "Epoch 226/500\n",
      "109222/109222 [==============================] - 22s 201us/step - loss: 3.4682 - accuracy: 0.2647\n",
      "Epoch 227/500\n",
      "109222/109222 [==============================] - 22s 201us/step - loss: 3.4642 - accuracy: 0.2659\n",
      "Epoch 228/500\n",
      "109222/109222 [==============================] - 22s 200us/step - loss: 3.4658 - accuracy: 0.2655\n",
      "Epoch 229/500\n",
      "109222/109222 [==============================] - 22s 201us/step - loss: 3.4606 - accuracy: 0.2667\n",
      "Epoch 230/500\n",
      "109222/109222 [==============================] - 22s 205us/step - loss: 3.4618 - accuracy: 0.2660\n",
      "Epoch 231/500\n",
      "109222/109222 [==============================] - 23s 214us/step - loss: 3.4587 - accuracy: 0.2665\n",
      "Epoch 232/500\n",
      "109222/109222 [==============================] - 48s 436us/step - loss: 3.4571 - accuracy: 0.2651\n",
      "Epoch 233/500\n",
      "109222/109222 [==============================] - 47s 434us/step - loss: 3.4566 - accuracy: 0.2670A: 0s - loss: 3.4567 - accura\n",
      "Epoch 234/500\n",
      "109222/109222 [==============================] - 50s 462us/step - loss: 3.4524 - accuracy: 0.2676\n",
      "Epoch 235/500\n",
      "109222/109222 [==============================] - 51s 464us/step - loss: 3.4507 - accuracy: 0.2677\n",
      "Epoch 236/500\n",
      "109222/109222 [==============================] - 50s 457us/step - loss: 3.4500 - accuracy: 0.2675\n",
      "Epoch 237/500\n",
      "109222/109222 [==============================] - 50s 462us/step - loss: 3.4513 - accuracy: 0.2684\n",
      "Epoch 238/500\n",
      "109222/109222 [==============================] - 50s 461us/step - loss: 3.4488 - accuracy: 0.2686\n",
      "Epoch 239/500\n",
      "109222/109222 [==============================] - 50s 461us/step - loss: 3.4453 - accuracy: 0.2678\n",
      "Epoch 240/500\n",
      "109222/109222 [==============================] - 51s 463us/step - loss: 3.4429 - accuracy: 0.2696\n",
      "Epoch 241/500\n",
      "109222/109222 [==============================] - 51s 463us/step - loss: 3.4423 - accuracy: 0.2686\n",
      "Epoch 242/500\n",
      "109222/109222 [==============================] - 51s 470us/step - loss: 3.4421 - accuracy: 0.2691\n",
      "Epoch 243/500\n",
      "109222/109222 [==============================] - 47s 429us/step - loss: 3.4403 - accuracy: 0.2689\n",
      "Epoch 244/500\n",
      "109222/109222 [==============================] - 54s 494us/step - loss: 3.4407 - accuracy: 0.2680\n",
      "Epoch 245/500\n",
      "109222/109222 [==============================] - 51s 466us/step - loss: 3.4371 - accuracy: 0.2694\n",
      "Epoch 246/500\n",
      "109222/109222 [==============================] - 51s 463us/step - loss: 3.4363 - accuracy: 0.2692s - loss: 3\n",
      "Epoch 247/500\n",
      "109222/109222 [==============================] - 51s 464us/step - loss: 3.4347 - accuracy: 0.2694\n",
      "Epoch 248/500\n",
      "109222/109222 [==============================] - 50s 462us/step - loss: 3.4318 - accuracy: 0.2709\n",
      "Epoch 249/500\n",
      "109222/109222 [==============================] - 51s 465us/step - loss: 3.4329 - accuracy: 0.2705\n",
      "Epoch 250/500\n",
      "109222/109222 [==============================] - 48s 440us/step - loss: 3.4333 - accuracy: 0.2703\n",
      "Epoch 251/500\n",
      "109222/109222 [==============================] - 49s 445us/step - loss: 3.4291 - accuracy: 0.2713\n",
      "Epoch 252/500\n",
      "109222/109222 [==============================] - 50s 462us/step - loss: 3.4275 - accuracy: 0.2707\n",
      "Epoch 253/500\n",
      "109222/109222 [==============================] - 50s 456us/step - loss: 3.4241 - accuracy: 0.2710\n",
      "Epoch 254/500\n",
      "109222/109222 [==============================] - 49s 448us/step - loss: 3.4234 - accuracy: 0.2724s - loss: 3.4226 - accura\n",
      "Epoch 255/500\n",
      "109222/109222 [==============================] - 48s 438us/step - loss: 3.4241 - accuracy: 0.2703\n",
      "Epoch 256/500\n",
      "109222/109222 [==============================] - 48s 435us/step - loss: 3.4221 - accuracy: 0.2719s - loss: 3.4222 - accuracy: 0.\n",
      "Epoch 257/500\n",
      "109222/109222 [==============================] - 51s 469us/step - loss: 3.4185 - accuracy: 0.2724\n",
      "Epoch 258/500\n",
      "109222/109222 [==============================] - 50s 455us/step - loss: 3.4182 - accuracy: 0.2725s - loss: 3.4180 - accuracy\n",
      "Epoch 259/500\n",
      "109222/109222 [==============================] - 50s 455us/step - loss: 3.4181 - accuracy: 0.2728\n",
      "Epoch 260/500\n",
      "109222/109222 [==============================] - 51s 471us/step - loss: 3.4192 - accuracy: 0.2718s - loss: 3.419\n",
      "Epoch 261/500\n",
      "109222/109222 [==============================] - 52s 474us/step - loss: 3.4161 - accuracy: 0.2731s - loss: 3.4158 - accuracy: 0.\n",
      "Epoch 262/500\n",
      "109222/109222 [==============================] - 49s 448us/step - loss: 3.4127 - accuracy: 0.2735\n",
      "Epoch 263/500\n",
      "109222/109222 [==============================] - 49s 450us/step - loss: 3.4107 - accuracy: 0.2731\n",
      "Epoch 264/500\n",
      "109222/109222 [==============================] - 50s 462us/step - loss: 3.4116 - accuracy: 0.2737\n",
      "Epoch 265/500\n",
      "109222/109222 [==============================] - 50s 461us/step - loss: 3.4084 - accuracy: 0.2739\n",
      "Epoch 266/500\n",
      "109222/109222 [==============================] - 51s 467us/step - loss: 3.4071 - accuracy: 0.2738\n",
      "Epoch 267/500\n",
      "109222/109222 [==============================] - 50s 453us/step - loss: 3.4064 - accuracy: 0.2740s - loss: 3\n",
      "Epoch 268/500\n",
      "109222/109222 [==============================] - 50s 456us/step - loss: 3.4078 - accuracy: 0.2737\n",
      "Epoch 269/500\n",
      "109222/109222 [==============================] - 58s 533us/step - loss: 3.4051 - accuracy: 0.2751\n",
      "Epoch 270/500\n",
      "109222/109222 [==============================] - ETA: 0s - loss: 3.4022 - accuracy: 0.27 - 53s 489us/step - loss: 3.4023 - accuracy: 0.2741\n",
      "Epoch 271/500\n",
      "109222/109222 [==============================] - 53s 489us/step - loss: 3.4026 - accuracy: 0.2745\n",
      "Epoch 272/500\n",
      "109222/109222 [==============================] - 52s 474us/step - loss: 3.4001 - accuracy: 0.2746\n",
      "Epoch 273/500\n",
      "109222/109222 [==============================] - 50s 462us/step - loss: 3.3988 - accuracy: 0.2751\n",
      "Epoch 274/500\n",
      "109222/109222 [==============================] - 61s 556us/step - loss: 3.3968 - accuracy: 0.2756\n",
      "Epoch 275/500\n",
      "109222/109222 [==============================] - 49s 444us/step - loss: 3.3941 - accuracy: 0.2755\n",
      "Epoch 276/500\n",
      "109222/109222 [==============================] - 53s 488us/step - loss: 3.3947 - accuracy: 0.2753\n",
      "Epoch 277/500\n",
      "109222/109222 [==============================] - 49s 452us/step - loss: 3.3952 - accuracy: 0.2750\n",
      "Epoch 278/500\n",
      "109222/109222 [==============================] - 48s 442us/step - loss: 3.3956 - accuracy: 0.2761\n",
      "Epoch 279/500\n",
      "109222/109222 [==============================] - 48s 438us/step - loss: 3.3920 - accuracy: 0.2759\n",
      "Epoch 280/500\n",
      "109222/109222 [==============================] - 49s 447us/step - loss: 3.3893 - accuracy: 0.2764\n",
      "Epoch 281/500\n",
      "109222/109222 [==============================] - 48s 438us/step - loss: 3.3901 - accuracy: 0.2768\n",
      "Epoch 282/500\n",
      "109222/109222 [==============================] - 49s 450us/step - loss: 3.3886 - accuracy: 0.2769\n",
      "Epoch 283/500\n",
      "109222/109222 [==============================] - 48s 444us/step - loss: 3.3858 - accuracy: 0.2769\n",
      "Epoch 284/500\n",
      "109222/109222 [==============================] - 50s 462us/step - loss: 3.3871 - accuracy: 0.2772\n",
      "Epoch 285/500\n",
      "109222/109222 [==============================] - 48s 443us/step - loss: 3.3798 - accuracy: 0.2791\n",
      "Epoch 286/500\n",
      "109222/109222 [==============================] - 50s 462us/step - loss: 3.3831 - accuracy: 0.2778\n",
      "Epoch 287/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109222/109222 [==============================] - 50s 461us/step - loss: 3.3823 - accuracy: 0.2785\n",
      "Epoch 288/500\n",
      "109222/109222 [==============================] - 46s 422us/step - loss: 3.3816 - accuracy: 0.2770\n",
      "Epoch 289/500\n",
      "109222/109222 [==============================] - 49s 446us/step - loss: 3.3769 - accuracy: 0.2788\n",
      "Epoch 290/500\n",
      "109222/109222 [==============================] - 49s 452us/step - loss: 3.3798 - accuracy: 0.2776\n",
      "Epoch 291/500\n",
      "109222/109222 [==============================] - 48s 440us/step - loss: 3.3778 - accuracy: 0.2777\n",
      "Epoch 292/500\n",
      "109222/109222 [==============================] - 50s 455us/step - loss: 3.3747 - accuracy: 0.2779\n",
      "Epoch 293/500\n",
      "109222/109222 [==============================] - 50s 459us/step - loss: 3.3743 - accuracy: 0.2787s - l\n",
      "Epoch 294/500\n",
      "109222/109222 [==============================] - 50s 454us/step - loss: 3.3725 - accuracy: 0.2789\n",
      "Epoch 295/500\n",
      "109222/109222 [==============================] - 50s 458us/step - loss: 3.3721 - accuracy: 0.2792\n",
      "Epoch 296/500\n",
      "109222/109222 [==============================] - 50s 456us/step - loss: 3.3716 - accuracy: 0.2799\n",
      "Epoch 297/500\n",
      "109222/109222 [==============================] - 52s 475us/step - loss: 3.3673 - accuracy: 0.2803\n",
      "Epoch 298/500\n",
      "109222/109222 [==============================] - 49s 449us/step - loss: 3.3686 - accuracy: 0.2786\n",
      "Epoch 299/500\n",
      "109222/109222 [==============================] - 50s 461us/step - loss: 3.3685 - accuracy: 0.2797s - ETA: 0s - loss: 3\n",
      "Epoch 300/500\n",
      "109222/109222 [==============================] - 51s 470us/step - loss: 3.3656 - accuracy: 0.2790\n",
      "Epoch 301/500\n",
      "109222/109222 [==============================] - 51s 463us/step - loss: 3.3638 - accuracy: 0.2805\n",
      "Epoch 302/500\n",
      "109222/109222 [==============================] - 50s 456us/step - loss: 3.3643 - accuracy: 0.2800\n",
      "Epoch 303/500\n",
      "109222/109222 [==============================] - 49s 450us/step - loss: 3.3624 - accuracy: 0.2798s - loss: 3 - ETA: \n",
      "Epoch 304/500\n",
      "109222/109222 [==============================] - 48s 442us/step - loss: 3.3605 - accuracy: 0.2798\n",
      "Epoch 305/500\n",
      "109222/109222 [==============================] - 49s 447us/step - loss: 3.3607 - accuracy: 0.2809\n",
      "Epoch 306/500\n",
      "109222/109222 [==============================] - 48s 440us/step - loss: 3.3572 - accuracy: 0.2812\n",
      "Epoch 307/500\n",
      "109222/109222 [==============================] - 51s 467us/step - loss: 3.3585 - accuracy: 0.2808\n",
      "Epoch 308/500\n",
      "109222/109222 [==============================] - 48s 435us/step - loss: 3.3582 - accuracy: 0.2813\n",
      "Epoch 309/500\n",
      "109222/109222 [==============================] - 50s 459us/step - loss: 3.3551 - accuracy: 0.2815\n",
      "Epoch 310/500\n",
      "109222/109222 [==============================] - 51s 466us/step - loss: 3.3528 - accuracy: 0.2823s - loss: 3.3528 - accuracy: \n",
      "Epoch 311/500\n",
      "109222/109222 [==============================] - 49s 446us/step - loss: 3.3527 - accuracy: 0.2818\n",
      "Epoch 312/500\n",
      "109222/109222 [==============================] - 49s 448us/step - loss: 3.3553 - accuracy: 0.2807\n",
      "Epoch 313/500\n",
      "109222/109222 [==============================] - 49s 449us/step - loss: 3.3514 - accuracy: 0.2827\n",
      "Epoch 314/500\n",
      "109222/109222 [==============================] - 49s 452us/step - loss: 3.3470 - accuracy: 0.2836\n",
      "Epoch 315/500\n",
      "109222/109222 [==============================] - 49s 449us/step - loss: 3.3485 - accuracy: 0.2824\n",
      "Epoch 316/500\n",
      "109222/109222 [==============================] - 52s 477us/step - loss: 3.3486 - accuracy: 0.2832\n",
      "Epoch 317/500\n",
      "109222/109222 [==============================] - 51s 463us/step - loss: 3.3450 - accuracy: 0.2834s - loss: 3.3444 - accura\n",
      "Epoch 318/500\n",
      "109222/109222 [==============================] - 49s 452us/step - loss: 3.3453 - accuracy: 0.2833\n",
      "Epoch 319/500\n",
      "109222/109222 [==============================] - 52s 476us/step - loss: 3.3465 - accuracy: 0.2821\n",
      "Epoch 320/500\n",
      "109222/109222 [==============================] - 50s 455us/step - loss: 3.3435 - accuracy: 0.2834\n",
      "Epoch 321/500\n",
      "109222/109222 [==============================] - 51s 463us/step - loss: 3.3431 - accuracy: 0.2833\n",
      "Epoch 322/500\n",
      "109222/109222 [==============================] - 50s 461us/step - loss: 3.3437 - accuracy: 0.2837\n",
      "Epoch 323/500\n",
      "109222/109222 [==============================] - 51s 470us/step - loss: 3.3404 - accuracy: 0.2836s - loss: 3.3326 - accuracy - ETA: 4s - l\n",
      "Epoch 324/500\n",
      "109222/109222 [==============================] - 53s 481us/step - loss: 3.3380 - accuracy: 0.2837\n",
      "Epoch 325/500\n",
      "109222/109222 [==============================] - 50s 454us/step - loss: 3.3399 - accuracy: 0.2831\n",
      "Epoch 326/500\n",
      "109222/109222 [==============================] - 49s 448us/step - loss: 3.3365 - accuracy: 0.2850\n",
      "Epoch 327/500\n",
      "109222/109222 [==============================] - 49s 447us/step - loss: 3.3357 - accuracy: 0.2850\n",
      "Epoch 328/500\n",
      "109222/109222 [==============================] - 50s 456us/step - loss: 3.3355 - accuracy: 0.2848\n",
      "Epoch 329/500\n",
      "109222/109222 [==============================] - 29s 268us/step - loss: 3.3371 - accuracy: 0.2851s - loss: 3.3364 - accuracy: \n",
      "Epoch 330/500\n",
      "109222/109222 [==============================] - 29s 269us/step - loss: 3.3319 - accuracy: 0.2858s - loss: 3.3311 - accuracy\n",
      "Epoch 331/500\n",
      "109222/109222 [==============================] - 26s 238us/step - loss: 3.3321 - accuracy: 0.2843\n",
      "Epoch 332/500\n",
      "109222/109222 [==============================] - 26s 239us/step - loss: 3.3302 - accuracy: 0.2853\n",
      "Epoch 333/500\n",
      "109222/109222 [==============================] - 26s 237us/step - loss: 3.3301 - accuracy: 0.2844\n",
      "Epoch 334/500\n",
      "109222/109222 [==============================] - 26s 236us/step - loss: 3.3308 - accuracy: 0.2851\n",
      "Epoch 335/500\n",
      "109222/109222 [==============================] - 27s 244us/step - loss: 3.3299 - accuracy: 0.2857\n",
      "Epoch 336/500\n",
      "109222/109222 [==============================] - 26s 236us/step - loss: 3.3243 - accuracy: 0.2854s - loss: 3.3234 - accu\n",
      "Epoch 337/500\n",
      "109222/109222 [==============================] - 26s 240us/step - loss: 3.3252 - accuracy: 0.2863\n",
      "Epoch 338/500\n",
      "109222/109222 [==============================] - 26s 242us/step - loss: 3.3253 - accuracy: 0.2858s\n",
      "Epoch 339/500\n",
      "109222/109222 [==============================] - 26s 240us/step - loss: 3.3228 - accuracy: 0.2873\n",
      "Epoch 340/500\n",
      "109222/109222 [==============================] - 26s 240us/step - loss: 3.3241 - accuracy: 0.2863\n",
      "Epoch 341/500\n",
      "109222/109222 [==============================] - 26s 237us/step - loss: 3.3207 - accuracy: 0.2857s - loss: 3.319\n",
      "Epoch 342/500\n",
      "109222/109222 [==============================] - 26s 239us/step - loss: 3.3208 - accuracy: 0.2866\n",
      "Epoch 343/500\n",
      "109222/109222 [==============================] - 26s 237us/step - loss: 3.3172 - accuracy: 0.2870\n",
      "Epoch 344/500\n",
      "109222/109222 [==============================] - 26s 242us/step - loss: 3.3200 - accuracy: 0.2870\n",
      "Epoch 345/500\n",
      "109222/109222 [==============================] - 26s 239us/step - loss: 3.3170 - accuracy: 0.2878\n",
      "Epoch 346/500\n",
      "109222/109222 [==============================] - 26s 237us/step - loss: 3.3153 - accuracy: 0.2878\n",
      "Epoch 347/500\n",
      "109222/109222 [==============================] - 27s 248us/step - loss: 3.3172 - accuracy: 0.2876\n",
      "Epoch 348/500\n",
      "109222/109222 [==============================] - 29s 262us/step - loss: 3.3132 - accuracy: 0.2882\n",
      "Epoch 349/500\n",
      "109222/109222 [==============================] - 26s 242us/step - loss: 3.3134 - accuracy: 0.2881\n",
      "Epoch 350/500\n",
      "109222/109222 [==============================] - 28s 253us/step - loss: 3.3134 - accuracy: 0.2884\n",
      "Epoch 351/500\n",
      "109222/109222 [==============================] - 27s 244us/step - loss: 3.3130 - accuracy: 0.2880\n",
      "Epoch 352/500\n",
      "109222/109222 [==============================] - 26s 241us/step - loss: 3.3118 - accuracy: 0.2889\n",
      "Epoch 353/500\n",
      "109222/109222 [==============================] - 27s 243us/step - loss: 3.3099 - accuracy: 0.2880\n",
      "Epoch 354/500\n",
      "109222/109222 [==============================] - 26s 239us/step - loss: 3.3080 - accuracy: 0.2890\n",
      "Epoch 355/500\n",
      "109222/109222 [==============================] - 28s 258us/step - loss: 3.3070 - accuracy: 0.2891\n",
      "Epoch 356/500\n",
      "109222/109222 [==============================] - 26s 236us/step - loss: 3.3069 - accuracy: 0.2889\n",
      "Epoch 357/500\n",
      "109222/109222 [==============================] - 27s 243us/step - loss: 3.3090 - accuracy: 0.2886\n",
      "Epoch 358/500\n",
      "109222/109222 [==============================] - 26s 239us/step - loss: 3.3051 - accuracy: 0.2889\n",
      "Epoch 359/500\n",
      "109222/109222 [==============================] - 26s 239us/step - loss: 3.3040 - accuracy: 0.2899\n",
      "Epoch 360/500\n",
      "109222/109222 [==============================] - 29s 262us/step - loss: 3.3018 - accuracy: 0.2894\n",
      "Epoch 361/500\n",
      "109222/109222 [==============================] - 26s 237us/step - loss: 3.3033 - accuracy: 0.2890\n",
      "Epoch 362/500\n",
      "109222/109222 [==============================] - 27s 243us/step - loss: 3.3010 - accuracy: 0.2908\n",
      "Epoch 363/500\n",
      "109222/109222 [==============================] - 28s 258us/step - loss: 3.3003 - accuracy: 0.2911\n",
      "Epoch 364/500\n",
      "109222/109222 [==============================] - 26s 240us/step - loss: 3.3000 - accuracy: 0.2898\n",
      "Epoch 365/500\n",
      "109222/109222 [==============================] - 26s 240us/step - loss: 3.3000 - accuracy: 0.2912\n",
      "Epoch 366/500\n",
      "109222/109222 [==============================] - 28s 252us/step - loss: 3.2998 - accuracy: 0.2904\n",
      "Epoch 367/500\n",
      "109222/109222 [==============================] - 28s 260us/step - loss: 3.2986 - accuracy: 0.2896\n",
      "Epoch 368/500\n",
      "109222/109222 [==============================] - 29s 266us/step - loss: 3.2967 - accuracy: 0.2903\n",
      "Epoch 369/500\n",
      "109222/109222 [==============================] - 27s 251us/step - loss: 3.2949 - accuracy: 0.2905\n",
      "Epoch 370/500\n",
      "109222/109222 [==============================] - 26s 238us/step - loss: 3.2932 - accuracy: 0.2911\n",
      "Epoch 371/500\n",
      "109222/109222 [==============================] - 26s 242us/step - loss: 3.2914 - accuracy: 0.2925\n",
      "Epoch 372/500\n",
      "109222/109222 [==============================] - 28s 258us/step - loss: 3.2936 - accuracy: 0.2902\n",
      "Epoch 373/500\n",
      "109222/109222 [==============================] - 27s 248us/step - loss: 3.2908 - accuracy: 0.2909\n",
      "Epoch 374/500\n",
      "109222/109222 [==============================] - 26s 239us/step - loss: 3.2930 - accuracy: 0.2922\n",
      "Epoch 375/500\n",
      "109222/109222 [==============================] - 28s 252us/step - loss: 3.2871 - accuracy: 0.2925\n",
      "Epoch 376/500\n",
      "109222/109222 [==============================] - 26s 241us/step - loss: 3.2897 - accuracy: 0.2917\n",
      "Epoch 377/500\n",
      "109222/109222 [==============================] - 30s 270us/step - loss: 3.2883 - accuracy: 0.2921\n",
      "Epoch 378/500\n",
      "109222/109222 [==============================] - 27s 245us/step - loss: 3.2865 - accuracy: 0.2923\n",
      "Epoch 379/500\n",
      "109222/109222 [==============================] - 27s 244us/step - loss: 3.2863 - accuracy: 0.2926\n",
      "Epoch 380/500\n",
      "109222/109222 [==============================] - 26s 242us/step - loss: 3.2862 - accuracy: 0.2914\n",
      "Epoch 381/500\n",
      "109222/109222 [==============================] - 26s 240us/step - loss: 3.2849 - accuracy: 0.2918\n",
      "Epoch 382/500\n",
      "109222/109222 [==============================] - 26s 238us/step - loss: 3.2827 - accuracy: 0.2913\n",
      "Epoch 383/500\n",
      "109222/109222 [==============================] - 26s 238us/step - loss: 3.2828 - accuracy: 0.2927\n",
      "Epoch 384/500\n",
      "109222/109222 [==============================] - 27s 245us/step - loss: 3.2819 - accuracy: 0.2931\n",
      "Epoch 385/500\n",
      "109222/109222 [==============================] - 26s 238us/step - loss: 3.2786 - accuracy: 0.2931\n",
      "Epoch 386/500\n",
      "109222/109222 [==============================] - 27s 243us/step - loss: 3.2829 - accuracy: 0.2933\n",
      "Epoch 387/500\n",
      "109222/109222 [==============================] - 26s 239us/step - loss: 3.2798 - accuracy: 0.2926\n",
      "Epoch 388/500\n",
      "109222/109222 [==============================] - 26s 241us/step - loss: 3.2773 - accuracy: 0.2941s - loss: 3.277\n",
      "Epoch 389/500\n",
      "109222/109222 [==============================] - 27s 247us/step - loss: 3.2785 - accuracy: 0.2928\n",
      "Epoch 390/500\n",
      "109222/109222 [==============================] - 26s 238us/step - loss: 3.2774 - accuracy: 0.2933\n",
      "Epoch 391/500\n",
      "109222/109222 [==============================] - 26s 240us/step - loss: 3.2729 - accuracy: 0.2949\n",
      "Epoch 392/500\n",
      "109222/109222 [==============================] - 26s 237us/step - loss: 3.2770 - accuracy: 0.2939\n",
      "Epoch 393/500\n",
      "109222/109222 [==============================] - 27s 244us/step - loss: 3.2730 - accuracy: 0.2961\n",
      "Epoch 394/500\n",
      "109222/109222 [==============================] - 26s 239us/step - loss: 3.2740 - accuracy: 0.2942\n",
      "Epoch 395/500\n",
      "109222/109222 [==============================] - 26s 242us/step - loss: 3.2742 - accuracy: 0.2946\n",
      "Epoch 396/500\n",
      "109222/109222 [==============================] - 27s 243us/step - loss: 3.2693 - accuracy: 0.2947\n",
      "Epoch 397/500\n",
      "109222/109222 [==============================] - 25s 231us/step - loss: 3.2721 - accuracy: 0.2936\n",
      "Epoch 398/500\n",
      "109222/109222 [==============================] - 26s 235us/step - loss: 3.2709 - accuracy: 0.2947\n",
      "Epoch 399/500\n",
      "109222/109222 [==============================] - 25s 231us/step - loss: 3.2698 - accuracy: 0.2955\n",
      "Epoch 400/500\n",
      "109222/109222 [==============================] - 25s 228us/step - loss: 3.2688 - accuracy: 0.2948\n",
      "Epoch 401/500\n",
      "109222/109222 [==============================] - 25s 228us/step - loss: 3.2687 - accuracy: 0.2946\n",
      "Epoch 402/500\n",
      "109222/109222 [==============================] - 25s 230us/step - loss: 3.2670 - accuracy: 0.2945\n",
      "Epoch 403/500\n",
      "109222/109222 [==============================] - 25s 230us/step - loss: 3.2654 - accuracy: 0.2957\n",
      "Epoch 404/500\n",
      "109222/109222 [==============================] - 25s 230us/step - loss: 3.2653 - accuracy: 0.2948\n",
      "Epoch 405/500\n",
      "109222/109222 [==============================] - 25s 228us/step - loss: 3.2645 - accuracy: 0.2950\n",
      "Epoch 406/500\n",
      "109222/109222 [==============================] - 25s 233us/step - loss: 3.2653 - accuracy: 0.2954\n",
      "Epoch 407/500\n",
      "109222/109222 [==============================] - 26s 239us/step - loss: 3.2610 - accuracy: 0.2964s - loss: 3.2608 - accuracy: \n",
      "Epoch 408/500\n",
      "109222/109222 [==============================] - 26s 239us/step - loss: 3.2632 - accuracy: 0.2958\n",
      "Epoch 409/500\n",
      "109222/109222 [==============================] - 24s 223us/step - loss: 3.2583 - accuracy: 0.2969\n",
      "Epoch 410/500\n",
      "109222/109222 [==============================] - 24s 217us/step - loss: 3.2593 - accuracy: 0.2961\n",
      "Epoch 411/500\n",
      "109222/109222 [==============================] - 24s 217us/step - loss: 3.2598 - accuracy: 0.2955\n",
      "Epoch 412/500\n",
      "109222/109222 [==============================] - 24s 224us/step - loss: 3.2587 - accuracy: 0.2960\n",
      "Epoch 413/500\n",
      "109222/109222 [==============================] - 24s 216us/step - loss: 3.2622 - accuracy: 0.2942\n",
      "Epoch 414/500\n",
      "109222/109222 [==============================] - 24s 215us/step - loss: 3.2552 - accuracy: 0.2964\n",
      "Epoch 415/500\n",
      "109222/109222 [==============================] - 24s 217us/step - loss: 3.2555 - accuracy: 0.2965\n",
      "Epoch 416/500\n",
      "109222/109222 [==============================] - 24s 215us/step - loss: 3.2553 - accuracy: 0.2970\n",
      "Epoch 417/500\n",
      "109222/109222 [==============================] - 24s 221us/step - loss: 3.2597 - accuracy: 0.2960\n",
      "Epoch 418/500\n",
      "109222/109222 [==============================] - 23s 215us/step - loss: 3.2527 - accuracy: 0.2975\n",
      "Epoch 419/500\n",
      "109222/109222 [==============================] - 23s 215us/step - loss: 3.2543 - accuracy: 0.2977\n",
      "Epoch 420/500\n",
      "109222/109222 [==============================] - 24s 217us/step - loss: 3.2515 - accuracy: 0.2978\n",
      "Epoch 421/500\n",
      "109222/109222 [==============================] - 23s 215us/step - loss: 3.2522 - accuracy: 0.2973\n",
      "Epoch 422/500\n",
      "109222/109222 [==============================] - 24s 219us/step - loss: 3.2527 - accuracy: 0.2976\n",
      "Epoch 423/500\n",
      "109222/109222 [==============================] - 24s 220us/step - loss: 3.2482 - accuracy: 0.2982\n",
      "Epoch 424/500\n",
      "109222/109222 [==============================] - 23s 215us/step - loss: 3.2485 - accuracy: 0.2973\n",
      "Epoch 425/500\n",
      "109222/109222 [==============================] - 23s 214us/step - loss: 3.2499 - accuracy: 0.2977\n",
      "Epoch 426/500\n",
      "109222/109222 [==============================] - 24s 217us/step - loss: 3.2477 - accuracy: 0.2974\n",
      "Epoch 427/500\n",
      "109222/109222 [==============================] - 24s 218us/step - loss: 3.2471 - accuracy: 0.2978\n",
      "Epoch 428/500\n",
      "109222/109222 [==============================] - 24s 216us/step - loss: 3.2450 - accuracy: 0.2982\n",
      "Epoch 429/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109222/109222 [==============================] - 23s 212us/step - loss: 3.2446 - accuracy: 0.2988\n",
      "Epoch 430/500\n",
      "109222/109222 [==============================] - 23s 210us/step - loss: 3.2460 - accuracy: 0.2980\n",
      "Epoch 431/500\n",
      "109222/109222 [==============================] - 23s 210us/step - loss: 3.2446 - accuracy: 0.2991\n",
      "Epoch 432/500\n",
      "109222/109222 [==============================] - 23s 212us/step - loss: 3.2440 - accuracy: 0.2995\n",
      "Epoch 433/500\n",
      "109222/109222 [==============================] - 24s 222us/step - loss: 3.2409 - accuracy: 0.2989\n",
      "Epoch 434/500\n",
      "109222/109222 [==============================] - 23s 209us/step - loss: 3.2399 - accuracy: 0.2990\n",
      "Epoch 435/500\n",
      "109222/109222 [==============================] - 22s 202us/step - loss: 3.2410 - accuracy: 0.2986\n",
      "Epoch 436/500\n",
      "109222/109222 [==============================] - 22s 202us/step - loss: 3.2406 - accuracy: 0.2991\n",
      "Epoch 437/500\n",
      "109222/109222 [==============================] - 22s 204us/step - loss: 3.2416 - accuracy: 0.2994\n",
      "Epoch 438/500\n",
      "109222/109222 [==============================] - 22s 206us/step - loss: 3.2364 - accuracy: 0.2996\n",
      "Epoch 439/500\n",
      "109222/109222 [==============================] - 22s 201us/step - loss: 3.2407 - accuracy: 0.2985\n",
      "Epoch 440/500\n",
      "109222/109222 [==============================] - 22s 204us/step - loss: 3.2330 - accuracy: 0.3004\n",
      "Epoch 441/500\n",
      "109222/109222 [==============================] - 22s 203us/step - loss: 3.2380 - accuracy: 0.2986\n",
      "Epoch 442/500\n",
      "109222/109222 [==============================] - 22s 202us/step - loss: 3.2364 - accuracy: 0.3001\n",
      "Epoch 443/500\n",
      "109222/109222 [==============================] - 23s 213us/step - loss: 3.2344 - accuracy: 0.3003\n",
      "Epoch 444/500\n",
      "109222/109222 [==============================] - 22s 204us/step - loss: 3.2334 - accuracy: 0.3000s - loss: 3.2333 - accuracy: 0.30\n",
      "Epoch 445/500\n",
      "109222/109222 [==============================] - 23s 212us/step - loss: 3.2312 - accuracy: 0.3008\n",
      "Epoch 446/500\n",
      "109222/109222 [==============================] - 22s 204us/step - loss: 3.2350 - accuracy: 0.3011\n",
      "Epoch 447/500\n",
      "109222/109222 [==============================] - 23s 211us/step - loss: 3.2317 - accuracy: 0.3004\n",
      "Epoch 448/500\n",
      "109222/109222 [==============================] - 23s 213us/step - loss: 3.2318 - accuracy: 0.3001\n",
      "Epoch 449/500\n",
      "109222/109222 [==============================] - 23s 208us/step - loss: 3.2332 - accuracy: 0.3000\n",
      "Epoch 450/500\n",
      "109222/109222 [==============================] - 22s 202us/step - loss: 3.2285 - accuracy: 0.3017\n",
      "Epoch 451/500\n",
      "109222/109222 [==============================] - 22s 205us/step - loss: 3.2278 - accuracy: 0.3011\n",
      "Epoch 452/500\n",
      "109222/109222 [==============================] - 22s 203us/step - loss: 3.2296 - accuracy: 0.3008\n",
      "Epoch 453/500\n",
      "109222/109222 [==============================] - 22s 202us/step - loss: 3.2293 - accuracy: 0.3009\n",
      "Epoch 454/500\n",
      "109222/109222 [==============================] - 23s 206us/step - loss: 3.2267 - accuracy: 0.3011\n",
      "Epoch 455/500\n",
      "109222/109222 [==============================] - 22s 202us/step - loss: 3.2277 - accuracy: 0.3014\n",
      "Epoch 456/500\n",
      "109222/109222 [==============================] - 22s 205us/step - loss: 3.2253 - accuracy: 0.3002\n",
      "Epoch 457/500\n",
      "109222/109222 [==============================] - 22s 203us/step - loss: 3.2273 - accuracy: 0.3020\n",
      "Epoch 458/500\n",
      "109222/109222 [==============================] - 22s 203us/step - loss: 3.2239 - accuracy: 0.3018\n",
      "Epoch 459/500\n",
      "109222/109222 [==============================] - 23s 209us/step - loss: 3.2245 - accuracy: 0.3025\n",
      "Epoch 460/500\n",
      "109222/109222 [==============================] - 22s 202us/step - loss: 3.2219 - accuracy: 0.3026\n",
      "Epoch 461/500\n",
      "109222/109222 [==============================] - 22s 204us/step - loss: 3.2222 - accuracy: 0.3021\n",
      "Epoch 462/500\n",
      "109222/109222 [==============================] - 22s 205us/step - loss: 3.2221 - accuracy: 0.3012\n",
      "Epoch 463/500\n",
      "109222/109222 [==============================] - 22s 201us/step - loss: 3.2212 - accuracy: 0.3024\n",
      "Epoch 464/500\n",
      "109222/109222 [==============================] - 22s 204us/step - loss: 3.2184 - accuracy: 0.3026\n",
      "Epoch 465/500\n",
      "109222/109222 [==============================] - 23s 207us/step - loss: 3.2229 - accuracy: 0.3017\n",
      "Epoch 466/500\n",
      "109222/109222 [==============================] - ETA: 0s - loss: 3.2173 - accuracy: 0.30 - 22s 203us/step - loss: 3.2173 - accuracy: 0.3035\n",
      "Epoch 467/500\n",
      "109222/109222 [==============================] - 22s 203us/step - loss: 3.2169 - accuracy: 0.3027\n",
      "Epoch 468/500\n",
      "109222/109222 [==============================] - 22s 202us/step - loss: 3.2185 - accuracy: 0.3025\n",
      "Epoch 469/500\n",
      "109222/109222 [==============================] - 22s 203us/step - loss: 3.2204 - accuracy: 0.3016\n",
      "Epoch 470/500\n",
      "109222/109222 [==============================] - 24s 218us/step - loss: 3.2149 - accuracy: 0.3038\n",
      "Epoch 471/500\n",
      "109222/109222 [==============================] - 25s 227us/step - loss: 3.2145 - accuracy: 0.3032s\n",
      "Epoch 472/500\n",
      "109222/109222 [==============================] - 27s 248us/step - loss: 3.2151 - accuracy: 0.3038\n",
      "Epoch 473/500\n",
      "109222/109222 [==============================] - 26s 241us/step - loss: 3.2160 - accuracy: 0.3037\n",
      "Epoch 474/500\n",
      "109222/109222 [==============================] - 26s 236us/step - loss: 3.2152 - accuracy: 0.3031\n",
      "Epoch 475/500\n",
      "109222/109222 [==============================] - 26s 242us/step - loss: 3.2141 - accuracy: 0.3036\n",
      "Epoch 476/500\n",
      "109222/109222 [==============================] - 26s 234us/step - loss: 3.2113 - accuracy: 0.3031\n",
      "Epoch 477/500\n",
      "109222/109222 [==============================] - 26s 238us/step - loss: 3.2096 - accuracy: 0.3033\n",
      "Epoch 478/500\n",
      "109222/109222 [==============================] - 25s 233us/step - loss: 3.2130 - accuracy: 0.3038\n",
      "Epoch 479/500\n",
      "109222/109222 [==============================] - 28s 256us/step - loss: 3.2096 - accuracy: 0.3041\n",
      "Epoch 480/500\n",
      "109222/109222 [==============================] - 32s 290us/step - loss: 3.2104 - accuracy: 0.3039\n",
      "Epoch 481/500\n",
      "109222/109222 [==============================] - 29s 268us/step - loss: 3.2066 - accuracy: 0.3046\n",
      "Epoch 482/500\n",
      "109222/109222 [==============================] - 29s 268us/step - loss: 3.2094 - accuracy: 0.3033\n",
      "Epoch 483/500\n",
      "109222/109222 [==============================] - 29s 268us/step - loss: 3.2070 - accuracy: 0.3051\n",
      "Epoch 484/500\n",
      "109222/109222 [==============================] - 29s 269us/step - loss: 3.2068 - accuracy: 0.3043\n",
      "Epoch 485/500\n",
      "109222/109222 [==============================] - 29s 263us/step - loss: 3.2058 - accuracy: 0.3043\n",
      "Epoch 486/500\n",
      "109222/109222 [==============================] - 27s 246us/step - loss: 3.2040 - accuracy: 0.3051\n",
      "Epoch 487/500\n",
      "109222/109222 [==============================] - 26s 240us/step - loss: 3.2058 - accuracy: 0.3043\n",
      "Epoch 488/500\n",
      "109222/109222 [==============================] - 27s 250us/step - loss: 3.2044 - accuracy: 0.3051\n",
      "Epoch 489/500\n",
      "109222/109222 [==============================] - 25s 233us/step - loss: 3.2036 - accuracy: 0.3051\n",
      "Epoch 490/500\n",
      "109222/109222 [==============================] - 26s 234us/step - loss: 3.2050 - accuracy: 0.3038\n",
      "Epoch 491/500\n",
      "109222/109222 [==============================] - 27s 246us/step - loss: 3.2039 - accuracy: 0.3053\n",
      "Epoch 492/500\n",
      "109222/109222 [==============================] - 28s 258us/step - loss: 3.2007 - accuracy: 0.3047\n",
      "Epoch 493/500\n",
      "109222/109222 [==============================] - 25s 224us/step - loss: 3.2035 - accuracy: 0.3050\n",
      "Epoch 494/500\n",
      "109222/109222 [==============================] - 25s 226us/step - loss: 3.2001 - accuracy: 0.3048\n",
      "Epoch 495/500\n",
      "109222/109222 [==============================] - 29s 265us/step - loss: 3.1978 - accuracy: 0.3055\n",
      "Epoch 496/500\n",
      "109222/109222 [==============================] - 29s 266us/step - loss: 3.2007 - accuracy: 0.3055\n",
      "Epoch 497/500\n",
      "109222/109222 [==============================] - 30s 271us/step - loss: 3.2025 - accuracy: 0.3045\n",
      "Epoch 498/500\n",
      "109222/109222 [==============================] - 30s 274us/step - loss: 3.1980 - accuracy: 0.3058\n",
      "Epoch 499/500\n",
      "109222/109222 [==============================] - 28s 254us/step - loss: 3.1979 - accuracy: 0.3060\n",
      "Epoch 500/500\n",
      "109222/109222 [==============================] - 28s 253us/step - loss: 3.1956 - accuracy: 0.3058\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulary_size, seq_len, input_length=seq_len))\n",
    "model.add(LSTM(50,return_sequences=True))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(50,activation='relu'))\n",
    "model.add(Dense(vocabulary_size, activation='softmax'))\n",
    "print(model.summary())\n",
    "# compile network\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(train_inputs,train_targets,epochs=500,verbose=1,batch_size=128)\n",
    "model.save(\"next_word_prediction_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "who is the\n",
      "who is the\n",
      "[64, 14, 1]\n",
      "[[64 14  1]]\n",
      "Next word suggestion: course\n",
      "Next word suggestion: lodge\n",
      "Next word suggestion: daughter\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "input_text = input().strip().lower()\n",
    "print(input_text)\n",
    "encoded_text = tokenizer.texts_to_sequences([input_text])[0]\n",
    "print(encoded_text)\n",
    "pad_encoded = pad_sequences([encoded_text], maxlen=seq_len, truncating='pre')\n",
    "print(pad_encoded)\n",
    "for i in (model.predict(pad_encoded)[0]).argsort()[-3:][::-1]:\n",
    "    pred_word = tokenizer.index_word[i]\n",
    "    print(\"Next word suggestion:\",pred_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
